{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement des packages et base de données\n",
        "Ce code nécessite la version 2.8 de Tensorflow-text. "
      ],
      "metadata": {
        "id": "JKLq7iX01vDz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvIC-pBU1rCX"
      },
      "outputs": [],
      "source": [
        "#chargement des packages\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import tensorflow_text as text\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chargement du jeu de données\n",
        "test_data=pd.read_parquet('mails_spam_clean.parquet')\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "AZhovagE2WV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration de la base de données"
      ],
      "metadata": {
        "id": "OKwn-Si02qko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.info() #2000 mails, aucune valeur manquante"
      ],
      "metadata": {
        "id": "_ReDOgtr2ftD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#renommer la base df\n",
        "df= test_data\n",
        "#il y autant de spams que de non-spams, la base est équilibrée\n",
        "df['Spam'].value_counts()"
      ],
      "metadata": {
        "id": "f1FjdjZf23mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating 2 new dataframe as df_ham , df_spam\n",
        "\n",
        "df_spam = df[df['Spam']==True]\n",
        "df_ham = df[df['Spam']==False]\n",
        "\n",
        "print(\"Taille des non-spams:\", df_ham.shape)\n",
        "print(\"Taille des spams:\", df_spam.shape)"
      ],
      "metadata": {
        "id": "7ctaJecg3S8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatener les spams et les non spams, en vue de construire la base de test et la base d'apprentissage\n",
        "df_balanced = pd.concat([df_spam , df_ham])"
      ],
      "metadata": {
        "id": "nUK6b6VV3k80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creer une variable \"spam\" qui vaut 1 pour \"Spam\", 0 pour \"non-spam\"\n",
        "df_balanced['spam'] = df_balanced['Spam'].apply(lambda x:1 if x==True else 0)"
      ],
      "metadata": {
        "id": "3DoLxcl3319i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced.sample(4)"
      ],
      "metadata": {
        "id": "VKrRSS5F4JGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construction des bases d'apprentissage et de test\n",
        "La variable cible y est la catégorie du mail : spam ou non. \n",
        "X contient les mots dans les mails correspondants à l'une ou l'autre catégorie. \n",
        "X_train et Y_train sont utilisées pour l'apprentissage et X_test et y_test pour le test. "
      ],
      "metadata": {
        "id": "rbDMSWuT4Ra9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split la base en X_train, X_test, y_train et y_test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test , y_train, y_test = train_test_split(df_balanced['body'], df_balanced['spam'],\n",
        "                                                    stratify = df_balanced['spam'])"
      ],
      "metadata": {
        "id": "9VSo9wMX4Y0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construction du modèle de BERT\n",
        "\n"
      ],
      "metadata": {
        "id": "HFgisxUB5Lnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# télécharger le préprocessing et l'encodage sur le site de BERT via Tensorflow\n",
        "bert_preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
        "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4')"
      ],
      "metadata": {
        "id": "k24e-VSn4OgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#on définit text_input pour y mettre les mots contenus dans le mail comme la couche 0\n",
        "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'Inputs')\n",
        "#on utilise la fonction bert_preprocessor() pour faire le processing des mots selon BERT\n",
        "preprocessed_text = bert_preprocessor(text_input)\n",
        "# embeed désigne le texte préprocessé encodé avec une fonction similaire de Bert pour l'encodage\n",
        "embeed = bert_encoder(preprocessed_text)\n",
        "# dropout donne l'entrée\n",
        "dropout = tf.keras.layers.Dropout(0.1, name = 'Dropout')(embeed['pooled_output'])\n",
        "# output donne la sortie de la couche \n",
        "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'Dense')(dropout)"
      ],
      "metadata": {
        "id": "NwGtZls65mmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating final model\n",
        "model = tf.keras.Model(inputs = [text_input], outputs = [outputs])"
      ],
      "metadata": {
        "id": "afeBObXl7t_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Voyons l'architecture du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "MxwqKK_j70C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apprentissage\n",
        "\n",
        "On construit et entraine notre modèle sur les bases X. "
      ],
      "metadata": {
        "id": "WgJxpVpa8Lzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating final model\n",
        "model = tf.keras.Model(inputs = [text_input], outputs = [outputs])"
      ],
      "metadata": {
        "id": "CFZiFV6178XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# afficher les métriques accuracy, precison, et recall pour chaque époque\n",
        "Metrics = [tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
        "           tf.keras.metrics.Precision(name = 'precision'),\n",
        "           tf.keras.metrics.Recall(name = 'recall')]"
      ],
      "metadata": {
        "id": "1-4ctJOL8fjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiler le modèle : on utilise l'optimizer adam et l'entropie binaire croisée pour la fonction de perte\n",
        "model.compile(optimizer ='adam',\n",
        "               loss = 'binary_crossentropy',\n",
        "               metrics = Metrics)"
      ],
      "metadata": {
        "id": "-SS8Y_ae8sX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# phase d'apprentissage : 10 époques suffisent\n",
        "history = model.fit(X_train, y_train, epochs = 10)"
      ],
      "metadata": {
        "id": "vPjy1LLD9E9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inlmGrPl9QFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle s'améliore au fur à mesure des époques : l'accuracy, le recall et la precision augmentent tandis que la perte diminue. \n",
        "# Evaluation du modèle\n",
        "Pour connaitre les métriques, on regarde les résultats pour la dernière couche. "
      ],
      "metadata": {
        "id": "Qg2k465F9Rjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "kwJu5OVr-QtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred est la prédiction de Bert entrainé sur nos données en fonction de X_test\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.flatten()"
      ],
      "metadata": {
        "id": "3CmhXx2l-Zq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#si un mail a plus de 50% de probilité d'être un spam, alors on lui attribue 1, 0 sinon.\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "2vNS1rtd_xuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Afficher les métriques d'évaluation accuracy, precision, recall\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#Graphique : matrice de confusion\n",
        "mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=True, cmap='coolwarm', linewidths=5)\n",
        "#titres des axes \n",
        "plt.xlabel('Valeur prédite')\n",
        "plt.ylabel('Valeur réelle')\n",
        "#montrer le graphique\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gLfoNeAtA3D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Le modèle de BERT est très intéressant du point de vue de la vectorisation, mais son classifier pourrait être amélioré. \n",
        "\n",
        "L'accuracy est de 84 %. Le classifier prédit très bien les spams, mais a tendance à ranger des non-spams dans les spams. "
      ],
      "metadata": {
        "id": "uk6IjFLhBBrg"
      }
    }
  ]
}